# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/115pr8bFOJfNsgZgkVYbKP3a165bo2G6i
"""
###Importacion de librerias

# Tratamiento de datos
# ==============================================================================
import polars as pl
import numpy as np
#from sklearn.preprocessing import StandardScaler
# Preprocesado y modelado
# ==============================================================================
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
#from sklearn.model_selection import train_test_split
#from sklearn.preprocessing import LabelEncoder
# Gráficos
# ==============================================================================
import matplotlib.pyplot as plt
from matplotlib import style
#from mlxtend.plotting import plot_decision_regions
# Configuración matplotlib
# ==============================================================================
plt.rcParams['image.cmap'] = "bwr"
plt.rcParams['figure.dpi'] = "100"
plt.rcParams['savefig.bbox'] = "tight"
style.use('ggplot') or plt.style.use('ggplot')
# Configuración warnings
# ==============================================================================
import warnings
warnings.filterwarnings('ignore')


# Lectura de datos
# ==============================================================================
Data = pl.read_csv('data/DataSet_Obesity.csv',infer_schema_length=10000)

"""
Seleccionamos la informacion que pasara el modelo
y la procesamos para que pueda ser leida.
El nivel de obesidad se basa en el índice de masa corporal
por tanto NObeyesdad estrechamente relacionada a las variables Weight y Heigth 
y por esta razón las quitaremos de nuestro modelo.
"""
#Seleccion de datos
# ==============================================================================
Data= Data.select (
      pl.when(pl.col('Gender') == 'Male').then(pl.lit(0))
      .otherwise(pl.lit(1))
      .alias('Gender'),
      pl.col('Age'),
      pl.when(pl.col('family_history_with_overweight') == 'no').then(pl.lit(0))
      .otherwise(pl.lit(1))
      .alias('fam_hist_overweight'),
      pl.when(pl.col('FAVC') == 'no').then(pl.lit(0))
      .otherwise(pl.lit(1))
      .alias('FAVC'),
      pl.col(['FCVC',	'NCP']),
      pl.when(pl.col('CAEC') == 'no').then(pl.lit(0))
      .when(pl.col('CAEC') == 'Sometimes').then(pl.lit(1))
      .when(pl.col('CAEC') == 'Frequently').then(pl.lit(2))
      .when(pl.col('CAEC') == 'Always').then(pl.lit(3))
      .alias('CAEC'),
      pl.when(pl.col('SMOKE') == 'no').then(pl.lit(0))
      .otherwise(pl.lit(1))
      .alias('SMOKE'),
      pl.col('CH2O'),
      pl.when(pl.col('SCC') == 'no').then(pl.lit(0))
      .otherwise(pl.lit(1))
      .alias('SCC'),
      pl.col(['FAF', 'TUE']),
      pl.when(pl.col('CALC') == 'no').then(pl.lit(0))
      .when(pl.col('CALC') == 'Sometimes').then(pl.lit(1))
      .when(pl.col('CALC') == 'Frequently').then(pl.lit(2))
      .when(pl.col('CALC') == 'Always').then(pl.lit(3))
      .alias('CALC'),
      pl.when(pl.col('NObeyesdad') == 'Insufficient_Weight').then(pl.lit(0))
      .when(pl.col('NObeyesdad') == 'Normal_Weight').then(pl.lit(1))
      .when(pl.col('NObeyesdad') == 'Overweight_Level_I').then(pl.lit(2))
      .when(pl.col('NObeyesdad') == 'Overweight_Level_II').then(pl.lit(3))
      .when(pl.col('NObeyesdad') == 'Obesity_Type_I').then(pl.lit(4))
      .when(pl.col('NObeyesdad') == 'Obesity_Type_II').then(pl.lit(5))
      .when(pl.col('NObeyesdad') == 'Obesity_Type_III').then(pl.lit(6))
      .alias('NObeyesdad')
      )

# División de los datos en train
# ==============================================================================
dtrain = pl.concat([Data.filter(pl.col('NObeyesdad')==0)[0:200],
                    Data.filter(pl.col('NObeyesdad')==1)[0:200],
                    Data.filter(pl.col('NObeyesdad')==2)[0:200],
                    Data.filter(pl.col('NObeyesdad')==3)[0:200],
                    Data.filter(pl.col('NObeyesdad')==4)[0:200],
                    Data.filter(pl.col('NObeyesdad')==5)[0:200],
                    Data.filter(pl.col('NObeyesdad')==6)[0:200]]
                   )
dtest = pl.concat([Data.filter(pl.col('NObeyesdad')==0)[201:],
                   Data.filter(pl.col('NObeyesdad')==1)[201:],
                   Data.filter(pl.col('NObeyesdad')==2)[201:],
                   Data.filter(pl.col('NObeyesdad')==3)[201:],
                   Data.filter(pl.col('NObeyesdad')==4)[201:],
                   Data.filter(pl.col('NObeyesdad')==5)[201:],
                   Data.filter(pl.col('NObeyesdad')==6)[201:]]
                   )
"""
El kernel usado es el radial por adaptabilidad a este dataset. 
El parámetro C se elgira entre un vector que variaremos en funcion de los resultados del modelo.
El parámetro gamma es scale aunque podriamos variar este parametro de misma forma que C.
Configurar gamma manualmente puede mejorar el desempeño pero complica el entrenmiento del modelo.
"""
# Grid de hiperparámetros
# ==============================================================================
param_grid = {'C': np.logspace(5.5, 6, 20)}

# Búsqueda por validación cruzada
# ==============================================================================
grid = GridSearchCV(
        estimator  = SVC(kernel= "rbf", gamma='scale'),
        param_grid = param_grid,
        scoring    = 'accuracy',
        n_jobs     = -1,
        cv         = 3,
        verbose    = 0,
        return_train_score = True
      )
grid.fit(X = dtrain.drop(columns = 'NObeyesdad'), y = dtrain['NObeyesdad'])
# Resultados del grid
# ==============================================================================
resultados = pl.DataFrame(grid.cv_results_)
resultados = resultados.select(pl.col(['param_C','mean_test_score','std_test_score','mean_train_score','std_train_score']))
resultados.sort('mean_test_score', descending=True).head()


# Grid de hiperparámetros
# ==============================================================================
print(param_grid )
# Mejores hiperparámetros por validación cruzada
# ==============================================================================
print("----------------------------------------")
print("Mejor hiperparámeto encontrado")
print("----------------------------------------")
print(grid.best_params_, ":", grid.best_score_, grid.scoring)

"""
Se repide desde el ultimo cometario largo hasta aqui a menos que
estes conforme de los resultados de los parámetros
"""

modelo = grid.best_estimator_

# Predicciones train
# ==============================================================================
predicciones = modelo.predict(dtrain.drop(columns='NObeyesdad'))
# Accuracy de test del modelo
# ==============================================================================
accuracy = accuracy_score(
            y_true    = dtrain['NObeyesdad'],
            y_pred    = predicciones,
            normalize = True
           )
print("")
print(f"El accuracy de test es: {100*accuracy}%")

# Matriz de confusión de las predicciones de train
# ==============================================================================
confusion_matrix = metrics.confusion_matrix(dtrain.select(pl.col('NObeyesdad')),predicciones)
# Crear la visualización de la matriz de confusión
labels = ['Insuf_W', 'N_W', 'Ov_Lv1',
          'Ov_Lv2', 'Ob_T1', 'Ob_T2', 'Ob_T3']
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = labels)
# Graficar la matriz de confusión
cm_display.plot()
plt.show()


# Predicciones test
# ==============================================================================
predicciones = modelo.predict(dtest.drop(columns='NObeyesdad'))
# Accuracy de test del modelo
# ==============================================================================
accuracy = accuracy_score(
            y_true    = dtest['NObeyesdad'],
            y_pred    = predicciones,
            normalize = True
           )
print("")
print(f"El accuracy de test es: {100*accuracy}%")

# Matriz de confusión de las predicciones de test
# ==============================================================================
confusion_matrix = metrics.confusion_matrix(dtest.select(pl.col('NObeyesdad')),predicciones)
# Crear la visualización de la matriz de confusión
labels = ['Insuf_W', 'N_W', 'Ov_Lv1',
          'Ov_Lv2', 'Ob_T1', 'Ob_T2', 'Ob_T3']
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = labels)
# Graficar la matriz de confusión
cm_display.plot()
plt.show()
